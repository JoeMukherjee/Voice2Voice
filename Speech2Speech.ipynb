{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting the server with Waitress...\n",
      "Serving on http://0.0.0.0:5001\n",
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpezf2xwfj.wav\n",
      "Error during request processing: name 'chat_history_ids' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Good morning, India.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import tempfile\n",
    "import requests\n",
    "import sounddevice as sd\n",
    "import wave\n",
    "import asyncio\n",
    "from flask import Flask, render_template, request, jsonify, Response\n",
    "from deepgram import Deepgram\n",
    "# from google import genai\n",
    "from waitress import serve\n",
    "import concurrent.futures\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the DialoGPT-medium model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "\n",
    "\n",
    "\n",
    "# API Configuration\n",
    "DEEPGRAM_API_KEY = \"14a53259c35bbe5d06ba288ed295228348aaebe6\"  \n",
    "ELEVEN_LABS_API_KEY = \"sk_b10646eba101273b1379f61958fec54857162174f82ec117\" \n",
    "ELEVEN_LABS_VOICE_ID = \"2EiwWnXFnvU5JabPnv8n\"\n",
    "# GEMINI_API_KEY = \"AIzaSyBkuNCgQNSvaCy1ci3F8eux0xEtwvrzFY8\"  \n",
    "\n",
    "# Initialize Flask App\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configure Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Initialize Gemini AI Client\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Missing GEMINI API Key. Set it as an environment variable.\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Initialize Deepgram Client\n",
    "dg_client = Deepgram(DEEPGRAM_API_KEY)\n",
    "\n",
    "# Chatbot State\n",
    "class State:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def get_messages(self):\n",
    "        return self.messages\n",
    "\n",
    "state = State()\n",
    "state.add_message(\"system\", \"You are a helpful servent of the royal family. Keep responses simple and royal.\")\n",
    "\n",
    "# # Generate AI Response using Google Gemini\n",
    "def call_model(state):\n",
    "    context = \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in state.get_messages()])\n",
    "    response = client.models.generate_content(model='gemini-2.0-flash-001', contents=context)\n",
    "    return response.text\n",
    "\n",
    "def get_chatbot_response(user_text):\n",
    "    state.add_message(\"user\", user_text)\n",
    "    response = call_model(state)\n",
    "    state.add_message(\"assistant\", response)\n",
    "    return response\n",
    "def get_chatbot_response(user_text):\n",
    "    global chat_history_ids\n",
    "\n",
    "    # Encode user input, add EOS token\n",
    "    new_user_input_ids = tokenizer.encode(user_text + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # If there's already chat history, append\n",
    "    if chat_history_ids is not None:\n",
    "        bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1)\n",
    "    else:\n",
    "        bot_input_ids = new_user_input_ids\n",
    "\n",
    "    # Generate a response (limit chat history to 1000 tokens)\n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        max_length=1000,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decode only the newly generated tokens\n",
    "    bot_response = tokenizer.decode(\n",
    "        chat_history_ids[:, bot_input_ids.shape[-1]:][0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    return bot_response\n",
    "\n",
    "\n",
    "# Convert Text to Speech using Eleven Labs\n",
    "def synthesize_speech(text):\n",
    "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{ELEVEN_LABS_VOICE_ID}/stream\"\n",
    "    headers = {\n",
    "        \"xi-api-key\": ELEVEN_LABS_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.5,\n",
    "            \"similarity_boost\": 0.75\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, stream=True, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            logging.error(f\"Speech synthesis failed: {response.text}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error during speech synthesis: {e}\")\n",
    "    return None\n",
    "\n",
    "# Record Audio from User\n",
    "def record_audio(duration=3, sample_rate=16000):\n",
    "    logging.info(\"Recording audio...\")\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    file_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\").name\n",
    "    with wave.open(file_path, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio_data.tobytes())\n",
    "    logging.info(f\"Audio saved at {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# Transcribe Audio using Deepgram\n",
    "async def transcribe_audio(file_path):\n",
    "    with open(file_path, 'rb') as audio:\n",
    "        source = {'buffer': audio, 'mimetype': 'audio/wav'}\n",
    "        result = await dg_client.transcription.prerecorded(source, {'punctuate': True})\n",
    "        alternatives = result['results']['channels'][0].get('alternatives', [])\n",
    "        return alternatives[0]['transcript'] if alternatives else \"(No speech detected)\"\n",
    "\n",
    "# Flask Routes\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "    \n",
    "@app.route('/start', methods=['POST'])\n",
    "def start_conversation():\n",
    "    try:\n",
    "        # 1) Record user speech\n",
    "        audio_file_path = record_audio()\n",
    "        user_text = asyncio.run(transcribe_audio(audio_file_path))\n",
    "        os.remove(audio_file_path)\n",
    "\n",
    "        if not user_text or user_text == \"(No speech detected)\":\n",
    "            return jsonify({\"error\": \"No speech detected, please try again.\"})\n",
    "\n",
    "        print(\"User:\", user_text)\n",
    "\n",
    "        # 2) Attempt to get DialoGPT response within 2 seconds\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(get_chatbot_response, user_text)\n",
    "            try:\n",
    "                bot_response = future.result(timeout=2)\n",
    "            except concurrent.futures.TimeoutError:\n",
    "                bot_response = \"I'm sorry, I didn't catch that. Please say again.\"\n",
    "\n",
    "        print(\"ChatBot:\", bot_response)\n",
    "\n",
    "        # 3) Convert Response to Speech (Eleven Labs)\n",
    "        speech_response = synthesize_speech(bot_response)\n",
    "        if speech_response:\n",
    "            return Response(speech_response.iter_content(chunk_size=1024), content_type=\"audio/mpeg\")\n",
    "\n",
    "        return jsonify({\"error\": \"Failed to generate speech response.\"})\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during request processing: {e}\")\n",
    "        return jsonify({\"error\": \"An error occurred while processing your request.\"})\n",
    "\n",
    "@app.route('/stop', methods=['POST'])\n",
    "def stop_conversation():\n",
    "    return jsonify({\"status\": \"Conversation stopped.\"})\n",
    "\n",
    "# Run Flask Server\n",
    "if __name__ == '__main__':\n",
    "    logging.info(\"Starting the server with Waitress...\")\n",
    "    serve(app, host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting the server with Waitress...\n",
      "Serving on http://0.0.0.0:5001\n",
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpl1_0vrea.wav\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hey brothers. Good morning.\n",
      "ChatBot: Good morning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpotf46nwa.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are you doing today?\n",
      "ChatBot: I'm going to a party.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmp2t5mvxv1.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Should we go and play with talk?\n",
      "ChatBot: I'm not sure what you mean by that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmphg7x8gvk.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Well, I'm talking about, you know, playing with dogs.\n",
      "ChatBot: I'm sorry, I didn't catch that. Please say again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpkw1zjspt.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I'm thinking you of playing with my dog.\n",
      "ChatBot: I'm thinking you of playing with my dog.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpyvhjd7sg.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Yeah. Exactly. My dog shi.\n",
      "ChatBot: I'm sorry for your loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpc41a7sw2.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: No. My dog doesn't die. You.\n",
      "ChatBot: I'm sorry for your loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmp999mfpeq.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Why are you sorry? You\n",
      "ChatBot: I'm sorry, I didn't catch that. Please say again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpj_hg6rbu.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I'm saying good morning.\n",
      "ChatBot: I'm saying good morning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmprg6_22uf.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Good morning to you too.\n",
      "ChatBot: Good morning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpap_72pp5.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Are you playing any games today?\n",
      "ChatBot: I'm playing a game of league of legends right now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmppwehmnuw.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Quiz cactus that you have?\n",
      "ChatBot: I have a few, but I'm not sure what they're worth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmp27dihdqr.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Which characters do you know of\n",
      "ChatBot: I'm sorry, I didn't catch that. Please say again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpq6114fak.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I said to which characters do you know op league of legends?\n",
      "ChatBot: I'm not sure what you're trying to say.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpc9f404sq.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Do even play league planes.\n",
      "ChatBot: I do, but I'm not a big fan of the game.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmp89_tyk2m.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Did we one give you know more about?\n",
      "ChatBot: I'm not sure, I just saw it on the front page.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmp8u5thqta.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: From page of what?\n",
      "ChatBot: The article.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpksa14g9x.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What do you really articles from?\n",
      "ChatBot: I'm not sure, but I think it's from the Onion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpockukqfz.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What Donnie?\n",
      "ChatBot: I think it's a reference to the movie Donnie Darko.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpxn7tkgi4.wav\n",
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpzmns5z4k.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What onion?\n",
      "ChatBot: The one that's in the picture.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmptla_qjk3.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Which picture?\n",
      "ChatBot: The one with the guy in the middle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpybuc2km7.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Describe me to picture.\n",
      "ChatBot: I'm a guy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved at C:\\Users\\NABANI~1\\AppData\\Local\\Temp\\tmpee4y5xhy.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What kind of guy?\n",
      "ChatBot: A guy who likes to party.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recording audio...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import tempfile\n",
    "import requests\n",
    "import sounddevice as sd\n",
    "import wave\n",
    "import asyncio\n",
    "from flask import Flask, render_template, request, jsonify, Response\n",
    "from deepgram import Deepgram\n",
    "from waitress import serve\n",
    "import concurrent.futures\n",
    "\n",
    "# --- DialoGPT Imports ---\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 1) Global chat_history_ids for multi-turn conversation\n",
    "chat_history_ids = None\n",
    "\n",
    "# 2) Load DialoGPT (Medium)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "\n",
    "# API Configuration\n",
    "DEEPGRAM_API_KEY = \"14a53259c35bbe5d06ba288ed295228348aaebe6\"\n",
    "ELEVEN_LABS_API_KEY = \"sk_b10646eba101273b1379f61958fec54857162174f82ec117\"\n",
    "ELEVEN_LABS_VOICE_ID = \"2EiwWnXFnvU5JabPnv8n\"\n",
    "\n",
    "# Initialize Flask App\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configure Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Initialize Deepgram\n",
    "dg_client = Deepgram(DEEPGRAM_API_KEY)\n",
    "\n",
    "# --- Synthesize Speech with Eleven Labs ---\n",
    "def synthesize_speech(text):\n",
    "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{ELEVEN_LABS_VOICE_ID}/stream\"\n",
    "    headers = {\n",
    "        \"xi-api-key\": ELEVEN_LABS_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.5,\n",
    "            \"similarity_boost\": 0.75\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, stream=True, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            logging.error(f\"Speech synthesis failed: {response.text}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error during speech synthesis: {e}\")\n",
    "    return None\n",
    "\n",
    "# --- Record Audio ---\n",
    "def record_audio(duration=3, sample_rate=16000):\n",
    "    logging.info(\"Recording audio...\")\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    file_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\").name\n",
    "    with wave.open(file_path, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio_data.tobytes())\n",
    "    logging.info(f\"Audio saved at {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# --- Transcribe Audio (Deepgram) ---\n",
    "async def transcribe_audio(file_path):\n",
    "    with open(file_path, 'rb') as audio:\n",
    "        source = {'buffer': audio, 'mimetype': 'audio/wav'}\n",
    "        result = await dg_client.transcription.prerecorded(source, {'punctuate': True})\n",
    "        alternatives = result['results']['channels'][0].get('alternatives', [])\n",
    "        return alternatives[0]['transcript'] if alternatives else \"(No speech detected)\"\n",
    "\n",
    "# --- Your Snippet: get_Chat_response ---\n",
    "def get_Chat_response(text):\n",
    "    \"\"\"\n",
    "    Chat for 5 lines, but effectively returns after first iteration due to 'return' inside the loop.\n",
    "    \"\"\"\n",
    "    global chat_history_ids\n",
    "\n",
    "    for step in range(5):\n",
    "        new_user_input_ids = tokenizer.encode(str(text) + tokenizer.eos_token, return_tensors='pt')\n",
    "        if step > 0:\n",
    "            bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1)\n",
    "        else:\n",
    "            bot_input_ids = new_user_input_ids\n",
    "\n",
    "        chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "        # This 'return' means we only see the first iteration\n",
    "        return tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "# --- Flask Routes ---\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/start', methods=['POST'])\n",
    "def start_conversation():\n",
    "    try:\n",
    "        # 1) Record User Speech\n",
    "        audio_file_path = record_audio()\n",
    "        user_text = asyncio.run(transcribe_audio(audio_file_path))\n",
    "        os.remove(audio_file_path)\n",
    "\n",
    "        if not user_text or user_text == \"(No speech detected)\":\n",
    "            return jsonify({\"error\": \"No speech detected, please try again.\"})\n",
    "\n",
    "        print(\"User:\", user_text)\n",
    "\n",
    "        # 2) Attempt to get DialoGPT snippet response within 2 seconds\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(get_Chat_response, user_text)\n",
    "            try:\n",
    "                bot_response = future.result(timeout=2)\n",
    "            except concurrent.futures.TimeoutError:\n",
    "                bot_response = \"I'm sorry, I didn't catch that. Please say again.\"\n",
    "\n",
    "        print(\"ChatBot:\", bot_response)\n",
    "\n",
    "        # 3) Convert to Speech (Eleven Labs)\n",
    "        speech_response = synthesize_speech(bot_response)\n",
    "        if speech_response:\n",
    "            return Response(speech_response.iter_content(chunk_size=1024), content_type=\"audio/mpeg\")\n",
    "\n",
    "        return jsonify({\"error\": \"Failed to generate speech response.\"})\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during request processing: {e}\")\n",
    "        return jsonify({\"error\": \"An error occurred while processing your request.\"})\n",
    "\n",
    "@app.route('/stop', methods=['POST'])\n",
    "def stop_conversation():\n",
    "    return jsonify({\"status\": \"Conversation stopped.\"})\n",
    "\n",
    "# --- Run Waitress ---\n",
    "if __name__ == '__main__':\n",
    "    logging.info(\"Starting the server with Waitress...\")\n",
    "    serve(app, host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
